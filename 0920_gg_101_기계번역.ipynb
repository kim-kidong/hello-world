{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0920_gg_101_기계번역.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kim-kidong/hello-world/blob/master/0920_gg_101_%E1%84%80%E1%85%B5%E1%84%80%E1%85%A8%E1%84%87%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oawi-8To_Z-p",
        "colab_type": "code",
        "outputId": "e720f653-a55f-4843-e1b1-dafef61f6b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!curl http://www.manythings.org/anki/kor-eng.zip -o kor-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 25348  100 25348    0     0  71202      0 --:--:-- --:--:-- --:--:-- 71202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61DXTqd3AaZW",
        "colab_type": "code",
        "outputId": "83baa94d-4349-4cd3-d92e-170017223583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kor-eng.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTrhWOA-_h5u",
        "colab_type": "code",
        "outputId": "433d0593-fa19-400e-bbd6-5110b3d8e6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!unzip kor-eng.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  kor-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: kor.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyM-j9T5zNih",
        "colab_type": "code",
        "outputId": "b492ab23-f0a7-42a6-c00c-2ea3b2911d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "!head -10 kor.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Who?\t누구?\n",
            "Hello!\t안녕!\n",
            "No way!\t절대 아니야.\n",
            "No way!\t그럴리가!\n",
            "Goodbye!\t안녕!\n",
            "I'm sad.\t슬퍼.\n",
            "Me, too.\t나도.\n",
            "Perfect!\t완벽해!\n",
            "Shut up!\t시끄러워!\n",
            "Welcome.\t어서오세요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOj5di1x_Ovm",
        "colab_type": "code",
        "outputId": "2a826c2d-0e68-4653-cea0-747745f7885c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Deep Learning Quick Reference Chapter 11: Seq2Seq\n",
        "# Mike Bernico <mike.bernico@gmail.com>\n",
        "# This program expects english to french sentance pairs located in chapter_11/data/\n",
        "# Dataset can be found at http://www.manythings.org/anki/fra-eng.zip\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.callbacks import TensorBoard\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def load_data(num_samples=50000, start_char='\\t', end_char='\\n', data_path='kor.txt'):\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "    input_characters = set()\n",
        "    target_characters = set()\n",
        "    lines = open(Path(data_path), 'r', encoding='utf-8').read().split('\\n')\n",
        "    for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "        input_text, target_text = line.split('\\t')\n",
        "        target_text = start_char + target_text + end_char\n",
        "        input_texts.append(input_text)\n",
        "        target_texts.append(target_text)\n",
        "        for char in input_text:\n",
        "            if char not in input_characters:\n",
        "                input_characters.add(char)\n",
        "        for char in target_text:\n",
        "            if char not in target_characters:\n",
        "                target_characters.add(char)\n",
        "\n",
        "    input_characters = sorted(list(input_characters))\n",
        "    target_characters = sorted(list(target_characters))\n",
        "    num_encoder_tokens = len(input_characters)\n",
        "    num_decoder_tokens = len(target_characters)\n",
        "    max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "    max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "    print('Number of samples:', len(input_texts))\n",
        "    print('Number of unique input tokens:', num_encoder_tokens)\n",
        "    print('Number of unique output tokens:', num_decoder_tokens)\n",
        "    print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "    print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "    return {'input_texts': input_texts, 'target_texts': target_texts,\n",
        "            'input_chars': input_characters, 'target_chars': target_characters,\n",
        "            'num_encoder_tokens': num_encoder_tokens, 'num_decoder_tokens': num_decoder_tokens,\n",
        "            'max_encoder_seq_length': max_encoder_seq_length, 'max_decoder_seq_length': max_decoder_seq_length}\n",
        "\n",
        "\n",
        "def one_hot_vectorize(data):\n",
        "    input_chars = data['input_chars']\n",
        "    target_chars = data['target_chars']\n",
        "    input_texts = data['input_texts']\n",
        "    target_texts = data['target_texts']\n",
        "    max_encoder_seq_length = data['max_encoder_seq_length']\n",
        "    max_decoder_seq_length = data['max_decoder_seq_length']\n",
        "    num_encoder_tokens = data['num_encoder_tokens']\n",
        "    num_decoder_tokens = data['num_decoder_tokens']\n",
        "\n",
        "    input_token_index = dict([(char, i) for i, char in enumerate(input_chars)])\n",
        "    target_token_index = dict([(char, i) for i, char in enumerate(target_chars)])\n",
        "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "        for t, char in enumerate(target_text):\n",
        "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "            decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "            if t > 0:\n",
        "                # decoder_target_data will be ahead by one timestep\n",
        "                # and will not include the start character.\n",
        "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    data['input_token_index'] = input_token_index\n",
        "    data['target_token_index'] = target_token_index\n",
        "    data['encoder_input_data'] = encoder_input_data\n",
        "    data['decoder_input_data'] = decoder_input_data\n",
        "    data['decoder_target_data'] = decoder_target_data\n",
        "    return data\n",
        "\n",
        "\n",
        "def build_models(lstm_units, num_encoder_tokens, num_decoder_tokens):\n",
        "    # train model\n",
        "    encoder_input = Input(shape=(None, num_encoder_tokens), name='encoder_input')\n",
        "    encoder_outputs, state_h, state_c = LSTM(lstm_units, return_state=True, name=\"encoder_lstm\")(encoder_input)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    decoder_input = Input(shape=(None, num_decoder_tokens), name='decoder_input')\n",
        "    decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True,\n",
        "                                 name=\"decoder_lstm\")\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_input, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='softmax_output')\n",
        "    decoder_output = decoder_dense(decoder_outputs)\n",
        "\n",
        "    model = Model([encoder_input, decoder_input], decoder_output)\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "    encoder_model = Model(encoder_input, encoder_states)\n",
        "\n",
        "    decoder_state_input_h = Input(shape=(lstm_units,))\n",
        "    decoder_state_input_c = Input(shape=(lstm_units,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_input, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = Model(\n",
        "        [decoder_input] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "\n",
        "    return model, encoder_model, decoder_model\n",
        "\n",
        "\n",
        "def create_callbacks(name):\n",
        "    tensorboard_callback = TensorBoard(log_dir=os.path.join(os.getcwd(), \"tb_log_char_s2s\", name),\n",
        "                                       write_graph=True,\n",
        "                                       write_grads=False)\n",
        "    return [tensorboard_callback]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlWe6vMk_wXT",
        "colab_type": "code",
        "outputId": "0576d8ac-4389-4a31-914c-9bc9260a6c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot\n",
        "\n",
        "data = load_data()\n",
        "data = one_hot_vectorize(data)\n",
        "# callbacks = create_callbacks(\"char_s2s\")\n",
        "model, encoder_model, decoder_model = build_models(256, data['num_encoder_tokens'], data['num_decoder_tokens'])\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "\n",
        "\n",
        "history = model.fit(x=[data[\"encoder_input_data\"], data[\"decoder_input_data\"]],\n",
        "          y=data[\"decoder_target_data\"],\n",
        "          batch_size=64,\n",
        "          epochs=400,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[es])\n",
        "#           callbacks=callbacks)\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "model.save('char_s2s_train.h5')\n",
        "encoder_model.save('char_s2s_encoder.h5')\n",
        "decoder_model.save('char_s2s_decoder.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 909\n",
            "Number of unique input tokens: 69\n",
            "Number of unique output tokens: 662\n",
            "Max sequence length for inputs: 124\n",
            "Max sequence length for outputs: 54\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      (None, None, 69)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_input (InputLayer)      (None, None, 662)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 256), (None, 333824      encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 256),  941056      decoder_input[0][0]              \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "softmax_output (Dense)          (None, None, 662)    170134      decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,445,014\n",
            "Trainable params: 1,445,014\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 727 samples, validate on 182 samples\n",
            "Epoch 1/400\n",
            "727/727 [==============================] - 6s 9ms/step - loss: 1.3396 - val_loss: 2.1194\n",
            "Epoch 2/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.1296 - val_loss: 2.1648\n",
            "Epoch 3/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.1150 - val_loss: 2.1026\n",
            "Epoch 4/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.1042 - val_loss: 2.1281\n",
            "Epoch 5/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.0939 - val_loss: 2.0759\n",
            "Epoch 6/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.0872 - val_loss: 2.0833\n",
            "Epoch 7/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.0740 - val_loss: 2.1491\n",
            "Epoch 8/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.0680 - val_loss: 2.2147\n",
            "Epoch 9/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.0562 - val_loss: 2.1350\n",
            "Epoch 10/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.0439 - val_loss: 2.0758\n",
            "Epoch 11/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.0260 - val_loss: 1.9882\n",
            "Epoch 12/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 1.0076 - val_loss: 1.9911\n",
            "Epoch 13/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.9999 - val_loss: 1.9822\n",
            "Epoch 14/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.9733 - val_loss: 1.9545\n",
            "Epoch 15/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.9530 - val_loss: 1.9476\n",
            "Epoch 16/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.9350 - val_loss: 1.8914\n",
            "Epoch 17/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.9216 - val_loss: 1.8555\n",
            "Epoch 18/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.9041 - val_loss: 1.8785\n",
            "Epoch 19/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.8893 - val_loss: 1.8082\n",
            "Epoch 20/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.8779 - val_loss: 1.8373\n",
            "Epoch 21/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.8637 - val_loss: 1.8333\n",
            "Epoch 22/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.8501 - val_loss: 1.8307\n",
            "Epoch 23/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.8424 - val_loss: 1.8233\n",
            "Epoch 24/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.8273 - val_loss: 1.7646\n",
            "Epoch 25/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.8171 - val_loss: 1.8085\n",
            "Epoch 26/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.8062 - val_loss: 1.7574\n",
            "Epoch 27/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7949 - val_loss: 1.7356\n",
            "Epoch 28/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7843 - val_loss: 1.7735\n",
            "Epoch 29/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7759 - val_loss: 1.7775\n",
            "Epoch 30/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7672 - val_loss: 1.7639\n",
            "Epoch 31/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7536 - val_loss: 1.7821\n",
            "Epoch 32/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7491 - val_loss: 1.7510\n",
            "Epoch 33/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7370 - val_loss: 1.7571\n",
            "Epoch 34/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7271 - val_loss: 1.7313\n",
            "Epoch 35/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7168 - val_loss: 1.7288\n",
            "Epoch 36/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.7085 - val_loss: 1.7442\n",
            "Epoch 37/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6994 - val_loss: 1.7564\n",
            "Epoch 38/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6916 - val_loss: 1.7420\n",
            "Epoch 39/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6819 - val_loss: 1.7404\n",
            "Epoch 40/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6701 - val_loss: 1.7314\n",
            "Epoch 41/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6638 - val_loss: 1.7213\n",
            "Epoch 42/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6544 - val_loss: 1.7208\n",
            "Epoch 43/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6457 - val_loss: 1.7451\n",
            "Epoch 44/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6345 - val_loss: 1.7392\n",
            "Epoch 45/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6315 - val_loss: 1.7170\n",
            "Epoch 46/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6193 - val_loss: 1.7303\n",
            "Epoch 47/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6094 - val_loss: 1.7255\n",
            "Epoch 48/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6022 - val_loss: 1.7431\n",
            "Epoch 49/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.5960 - val_loss: 1.7001\n",
            "Epoch 50/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.5843 - val_loss: 1.7549\n",
            "Epoch 51/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.5768 - val_loss: 1.7268\n",
            "Epoch 52/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.5706 - val_loss: 1.7279\n",
            "Epoch 53/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6273 - val_loss: 1.7812\n",
            "Epoch 54/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.6931 - val_loss: 1.7090\n",
            "Epoch 55/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.5711 - val_loss: 1.7269\n",
            "Epoch 56/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.5675 - val_loss: 1.7173\n",
            "Epoch 57/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.5755 - val_loss: 1.7228\n",
            "Epoch 58/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.5340 - val_loss: 1.7289\n",
            "Epoch 59/400\n",
            "727/727 [==============================] - 3s 4ms/step - loss: 0.5345 - val_loss: 1.7045\n",
            "Epoch 00059: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm_9/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'encoder_lstm_9/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_11:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'input_12:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6Dt_SlQC3mj",
        "colab_type": "code",
        "outputId": "8cb4197a-33f7-4675-9ba9-a1b34fafb252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_about.txt\t     char_s2s_train.h5\tkor-eng.zip  tb_log_char_s2s\n",
            "char_s2s_decoder.h5  fra-eng.zip\tkor.txt\n",
            "char_s2s_encoder.h5  fra.txt\t\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4mL8K1wC4ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "# from train_char_seq2seq import load_data, one_hot_vectorize\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_models():\n",
        "    model = load_model('char_s2s_train.h5')\n",
        "    encoder_model = load_model('char_s2s_encoder.h5')\n",
        "    decoder_model = load_model('char_s2s_decoder.h5')\n",
        "    return [model, encoder_model, decoder_model]\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq, data, encoder_model, decoder_model):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, data['num_decoder_tokens']))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, data['target_token_index']['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = data[\"reverse_target_char_index\"][sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > data['max_decoder_seq_length']):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, data['num_decoder_tokens']))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "def create_reverse_indicies(data):\n",
        "    data['reverse_input_char_index'] = dict(\n",
        "        (i, char) for char, i in data[\"input_token_index\"].items())\n",
        "    data['reverse_target_char_index'] = dict(\n",
        "        (i, char) for char, i in data[\"target_token_index\"].items())\n",
        "    return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71OK-denGfP6",
        "colab_type": "code",
        "outputId": "04aa67c6-2209-4a61-a74b-5f1869c5b52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data = load_data()\n",
        "data = one_hot_vectorize(data)\n",
        "data = create_reverse_indicies(data)\n",
        "model, encoder_model, decoder_model = load_models()\n",
        "\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = data[\"encoder_input_data\"][seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq, data, encoder_model, decoder_model)\n",
        "    print('-')\n",
        "    print('Input sentence:', data['input_texts'][seq_index])\n",
        "    print('Correct Translation:', data['target_texts'][seq_index].strip(\"\\t\\n\"))\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 909\n",
            "Number of unique input tokens: 69\n",
            "Number of unique output tokens: 662\n",
            "Max sequence length for inputs: 124\n",
            "Max sequence length for outputs: 54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Who?\n",
            "Correct Translation: 누구?\n",
            "Decoded sentence: 좋아하는 가수는 누구예요?\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Correct Translation: 안녕!\n",
            "Decoded sentence: 우리는 톰과 즐거운 시간을 가졌다.\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Correct Translation: 절대 아니야.\n",
            "Decoded sentence: 나도 너랑 같은 처지야.\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Correct Translation: 그럴리가!\n",
            "Decoded sentence: 나도 너랑 같은 처지야.\n",
            "\n",
            "-\n",
            "Input sentence: Goodbye!\n",
            "Correct Translation: 안녕!\n",
            "Decoded sentence: 우리는 그 사건을 검토할 필요가 있다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sad.\n",
            "Correct Translation: 슬퍼.\n",
            "Decoded sentence: 나도 너랑 같은 처지야.\n",
            "\n",
            "-\n",
            "Input sentence: Me, too.\n",
            "Correct Translation: 나도.\n",
            "Decoded sentence: 그건 무슨 언어였지?\n",
            "\n",
            "-\n",
            "Input sentence: Perfect!\n",
            "Correct Translation: 완벽해!\n",
            "Decoded sentence: 이게 대체 뭐예요?\n",
            "\n",
            "-\n",
            "Input sentence: Shut up!\n",
            "Correct Translation: 시끄러워!\n",
            "Decoded sentence: 우리는 그 사건을 검토할 필요가 있다.\n",
            "\n",
            "-\n",
            "Input sentence: Welcome.\n",
            "Correct Translation: 어서오세요.\n",
            "Decoded sentence: 거짓말 하지 마세요.\n",
            "\n",
            "-\n",
            "Input sentence: Welcome.\n",
            "Correct Translation: 환영합니다.\n",
            "Decoded sentence: 거짓말 하지 마세요.\n",
            "\n",
            "-\n",
            "Input sentence: Cheer up!\n",
            "Correct Translation: 힘내!\n",
            "Decoded sentence: 이 번호로 전화해.\n",
            "\n",
            "-\n",
            "Input sentence: Get lost.\n",
            "Correct Translation: 꺼져.\n",
            "Decoded sentence: 우리는 톰과 즐거운 시간을 가졌다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm ugly.\n",
            "Correct Translation: 나는 못 생겼다.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: It hurts.\n",
            "Correct Translation: 아파.\n",
            "Decoded sentence: 나도 행복하고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: Let's go!\n",
            "Correct Translation: 가자!\n",
            "Decoded sentence: 이제 충분히 했습니다.\n",
            "\n",
            "-\n",
            "Input sentence: Don't lie.\n",
            "Correct Translation: 거짓말 하지 마.\n",
            "Decoded sentence: 거짓말 하지 마세요.\n",
            "\n",
            "-\n",
            "Input sentence: Don't lie.\n",
            "Correct Translation: 거짓말 하지 마세요.\n",
            "Decoded sentence: 거짓말 하지 마세요.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sorry.\n",
            "Correct Translation: 미안해.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sorry.\n",
            "Correct Translation: 미안해요.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sorry.\n",
            "Correct Translation: 죄송합니다.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sorry.\n",
            "Correct Translation: 유감입니다.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: Of course.\n",
            "Correct Translation: 물론이죠.\n",
            "Decoded sentence: 이제 충분히 했습니다.\n",
            "\n",
            "-\n",
            "Input sentence: Seriously?\n",
            "Correct Translation: 진심이야?\n",
            "Decoded sentence: 우리는 톰과 즐거운 시간을 가졌다.\n",
            "\n",
            "-\n",
            "Input sentence: Take care.\n",
            "Correct Translation: 주의하세요.\n",
            "Decoded sentence: 그녀는 우울하다.\n",
            "\n",
            "-\n",
            "Input sentence: Be careful.\n",
            "Correct Translation: 조심해!\n",
            "Decoded sentence: 거짓말 하지 마세요.\n",
            "\n",
            "-\n",
            "Input sentence: He is nice.\n",
            "Correct Translation: 걔 괜찮아.\n",
            "Decoded sentence: 그는 그 문제로 난처해졌다.\n",
            "\n",
            "-\n",
            "Input sentence: Hold still.\n",
            "Correct Translation: 가만히 있으세요.\n",
            "Decoded sentence: 어찌나 사랑스러운지!\n",
            "\n",
            "-\n",
            "Input sentence: Hold still.\n",
            "Correct Translation: 가만히 있어.\n",
            "Decoded sentence: 어찌나 사랑스러운지!\n",
            "\n",
            "-\n",
            "Input sentence: How lovely!\n",
            "Correct Translation: 어찌나 사랑스러운지!\n",
            "Decoded sentence: 가만히 있어.\n",
            "\n",
            "-\n",
            "Input sentence: I felt bad.\n",
            "Correct Translation: 난 기분이 나빴다.\n",
            "Decoded sentence: 나도 몰라.\n",
            "\n",
            "-\n",
            "Input sentence: Is that OK?\n",
            "Correct Translation: 괜찮은 거예요?\n",
            "Decoded sentence: 이거 내꺼니?\n",
            "\n",
            "-\n",
            "Input sentence: Love hurts.\n",
            "Correct Translation: 사랑은 아프다.\n",
            "Decoded sentence: 나도 너랑 같은 처지야.\n",
            "\n",
            "-\n",
            "Input sentence: Boys do cry.\n",
            "Correct Translation: 남자애도 운다.\n",
            "Decoded sentence: 우리 애들은 학교에 있어요.\n",
            "\n",
            "-\n",
            "Input sentence: I don't lie.\n",
            "Correct Translation: 나는 거짓말 하지 않습니다.\n",
            "Decoded sentence: 나도 몰라.\n",
            "\n",
            "-\n",
            "Input sentence: I don't lie.\n",
            "Correct Translation: 난 거짓말 안해.\n",
            "Decoded sentence: 나도 몰라.\n",
            "\n",
            "-\n",
            "Input sentence: I don't lie.\n",
            "Correct Translation: 나는 거짓말 하지 않아.\n",
            "Decoded sentence: 나도 몰라.\n",
            "\n",
            "-\n",
            "Input sentence: I'm nervous.\n",
            "Correct Translation: 긴장돼요.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm nervous.\n",
            "Correct Translation: 떨려요.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm shocked.\n",
            "Correct Translation: 충격이야.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: It's a pity.\n",
            "Correct Translation: 안타까워요.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: What's that?\n",
            "Correct Translation: 저건 뭐야?\n",
            "Decoded sentence: 그건 무슨 언어였지?\n",
            "\n",
            "-\n",
            "Input sentence: You're mine.\n",
            "Correct Translation: 넌 내 거야.\n",
            "Decoded sentence: 이야기를 마저 들어보자.\n",
            "\n",
            "-\n",
            "Input sentence: You're mine.\n",
            "Correct Translation: 당신은 나의 것입니다.\n",
            "Decoded sentence: 이야기를 마저 들어보자.\n",
            "\n",
            "-\n",
            "Input sentence: Blood is red.\n",
            "Correct Translation: 피는 붉다.\n",
            "Decoded sentence: 좋아하는 가수는 누구예요?\n",
            "\n",
            "-\n",
            "Input sentence: Can I go now?\n",
            "Correct Translation: 이제 가도 되나요?\n",
            "Decoded sentence: 이 번호로 전화해.\n",
            "\n",
            "-\n",
            "Input sentence: Come quickly!\n",
            "Correct Translation: 빨리 와!\n",
            "Decoded sentence: 이 번호로 전화해.\n",
            "\n",
            "-\n",
            "Input sentence: Come quickly!\n",
            "Correct Translation: 빨리 오세요!\n",
            "Decoded sentence: 이 번호로 전화해.\n",
            "\n",
            "-\n",
            "Input sentence: Don't eat it.\n",
            "Correct Translation: 먹지 마.\n",
            "Decoded sentence: 거짓말 하지 마세요.\n",
            "\n",
            "-\n",
            "Input sentence: I don't know.\n",
            "Correct Translation: 나는 몰라요.\n",
            "Decoded sentence: 나는 그것을 버리고 싶지 않다.\n",
            "\n",
            "-\n",
            "Input sentence: I hate liars.\n",
            "Correct Translation: 난 거짓말쟁이가 싫어.\n",
            "Decoded sentence: 나는 내년에 중국어를 배우고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I need money.\n",
            "Correct Translation: 돈이 필요해요.\n",
            "Decoded sentence: 나는 내년에 중국어를 배우고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: Is that okay?\n",
            "Correct Translation: 괜찮은 거예요?\n",
            "Decoded sentence: 이거 내꺼니?\n",
            "\n",
            "-\n",
            "Input sentence: Is this mine?\n",
            "Correct Translation: 이거 내꺼니?\n",
            "Decoded sentence: 이거 내꺼니?\n",
            "\n",
            "-\n",
            "Input sentence: Is this wine?\n",
            "Correct Translation: 이게 와인이야?\n",
            "Decoded sentence: 이거 내꺼니?\n",
            "\n",
            "-\n",
            "Input sentence: It's suicide.\n",
            "Correct Translation: 자살입니다.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: Just keep it.\n",
            "Correct Translation: 그냥 그거 가져.\n",
            "Decoded sentence: 그건 무슨 언어였지?\n",
            "\n",
            "-\n",
            "Input sentence: We don't lie.\n",
            "Correct Translation: 우리는 거짓말을 하지 않아요.\n",
            "Decoded sentence: 우리는 톰과 즐거운 시간을 가졌다.\n",
            "\n",
            "-\n",
            "Input sentence: We don't lie.\n",
            "Correct Translation: 우린 거짓말 안해.\n",
            "Decoded sentence: 우리는 톰과 즐거운 시간을 가졌다.\n",
            "\n",
            "-\n",
            "Input sentence: We're inside.\n",
            "Correct Translation: 우리 안에 들어와 있어.\n",
            "Decoded sentence: 우리는 톰과 즐거운 시간을 가졌다.\n",
            "\n",
            "-\n",
            "Input sentence: We're inside.\n",
            "Correct Translation: 우린 안에 있어요.\n",
            "Decoded sentence: 우리는 톰과 즐거운 시간을 가졌다.\n",
            "\n",
            "-\n",
            "Input sentence: What is that?\n",
            "Correct Translation: 저것은 무엇입니까?\n",
            "Decoded sentence: 그가 여기에 오면 저한테 말해주세요.\n",
            "\n",
            "-\n",
            "Input sentence: Can I ask why?\n",
            "Correct Translation: 이유를 물어봐도 돼?\n",
            "Decoded sentence: 이 번호로 전화해.\n",
            "\n",
            "-\n",
            "Input sentence: Grab the rope.\n",
            "Correct Translation: 로프를 잡으세요.\n",
            "Decoded sentence: 이게 대체 뭐예요?\n",
            "\n",
            "-\n",
            "Input sentence: I am homesick.\n",
            "Correct Translation: 나 향수병 걸렸어.\n",
            "Decoded sentence: 나도 행복하고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I can't sleep.\n",
            "Correct Translation: 잠이 와.\n",
            "Decoded sentence: 나도 행복하고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I feel guilty.\n",
            "Correct Translation: 죄책감이 들어.\n",
            "Decoded sentence: 나도 몰라.\n",
            "\n",
            "-\n",
            "Input sentence: I hate myself.\n",
            "Correct Translation: 나는 내 자신이 싫어.\n",
            "Decoded sentence: 나는 내년에 중국어를 배우고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I smell blood.\n",
            "Correct Translation: 피 냄새가 납니다.\n",
            "Decoded sentence: 나도 행복하고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I use Firefox.\n",
            "Correct Translation: 나는 파이어폭스를 사용해.\n",
            "Decoded sentence: 나는 내년에 중국어를 배우고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I want to die.\n",
            "Correct Translation: 죽고 싶어요.\n",
            "Decoded sentence: 나에게 사전이 있다.\n",
            "\n",
            "-\n",
            "Input sentence: I want to die.\n",
            "Correct Translation: 죽고 싶어.\n",
            "Decoded sentence: 나에게 사전이 있다.\n",
            "\n",
            "-\n",
            "Input sentence: I'll kill him.\n",
            "Correct Translation: 나는 그를 죽일 것이다.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm depressed.\n",
            "Correct Translation: 우울해.\n",
            "Decoded sentence: 나도 같은 처지다.\n",
            "\n",
            "-\n",
            "Input sentence: Is that blood?\n",
            "Correct Translation: 그거 피야?\n",
            "Decoded sentence: 이거 내꺼니?\n",
            "\n",
            "-\n",
            "Input sentence: My head hurts.\n",
            "Correct Translation: 머리가 아파요.\n",
            "Decoded sentence: 내 친구는 슈퍼마켓에서 일해.\n",
            "\n",
            "-\n",
            "Input sentence: Tom is honest.\n",
            "Correct Translation: 톰은 정직하다.\n",
            "Decoded sentence: 톰은 그의 차를 메리에게 팔았다.\n",
            "\n",
            "-\n",
            "Input sentence: We want peace.\n",
            "Correct Translation: 우리는 평화를 원합니다.\n",
            "Decoded sentence: 우리는 톰과 즐거운 시간을 가졌다.\n",
            "\n",
            "-\n",
            "Input sentence: Autumn is here.\n",
            "Correct Translation: 가을이 되었습니다.\n",
            "Decoded sentence: 내 친구는 슈퍼마켓에서 일해.\n",
            "\n",
            "-\n",
            "Input sentence: Autumn is here.\n",
            "Correct Translation: 가을이 왔어요.\n",
            "Decoded sentence: 내 친구는 슈퍼마켓에서 일해.\n",
            "\n",
            "-\n",
            "Input sentence: Can I help you?\n",
            "Correct Translation: 제가 좀 도와 드릴까요?\n",
            "Decoded sentence: 이 번호로 전화해.\n",
            "\n",
            "-\n",
            "Input sentence: Do you hear me?\n",
            "Correct Translation: 제 말이 들리세요?\n",
            "Decoded sentence: 좋아하는 가수는 누구예요?\n",
            "\n",
            "-\n",
            "Input sentence: He was hard up.\n",
            "Correct Translation: 그는 돈에 쪼들리고 있었다.\n",
            "Decoded sentence: 그는 그 문제로 난처해졌다.\n",
            "\n",
            "-\n",
            "Input sentence: I don't buy it.\n",
            "Correct Translation: 못 믿어.\n",
            "Decoded sentence: 나는 그것을 버리고 싶지 않다.\n",
            "\n",
            "-\n",
            "Input sentence: I like reading.\n",
            "Correct Translation: 독서를 좋아합니다.\n",
            "Decoded sentence: 나도 행복하고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I love lasagna.\n",
            "Correct Translation: 저는 라자냐를 좋아해요.\n",
            "Decoded sentence: 나는 내년에 중국어를 배우고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I love my home.\n",
            "Correct Translation: 난 내 집이 좋아.\n",
            "Decoded sentence: 나는 내년에 중국어를 배우고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I study Korean.\n",
            "Correct Translation: 한국말을 공부합니다.\n",
            "Decoded sentence: 나는 내년에 중국어를 배우고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm very sorry.\n",
            "Correct Translation: 정말 미안해.\n",
            "Decoded sentence: 나도 행복하고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: I'm very sorry.\n",
            "Correct Translation: 정말 죄송합니다.\n",
            "Decoded sentence: 나도 행복하고 싶다.\n",
            "\n",
            "-\n",
            "Input sentence: Keep Tom there.\n",
            "Correct Translation: 톰은 여기에 두세요.\n",
            "Decoded sentence: 내가 도와줄게.\n",
            "\n",
            "-\n",
            "Input sentence: Only God knows.\n",
            "Correct Translation: 신만이 아실 것입니다.\n",
            "Decoded sentence: 이 사전은 비싸다.\n",
            "\n",
            "-\n",
            "Input sentence: Read this book.\n",
            "Correct Translation: 이 책 읽어.\n",
            "Decoded sentence: 이 흙에서는 아무것도 자라지 않는 것으로 보인다.\n",
            "\n",
            "-\n",
            "Input sentence: Read this book.\n",
            "Correct Translation: 이 책을 읽으세요.\n",
            "Decoded sentence: 이 흙에서는 아무것도 자라지 않는 것으로 보인다.\n",
            "\n",
            "-\n",
            "Input sentence: Sorry I'm late.\n",
            "Correct Translation: 늦어서 미안해.\n",
            "Decoded sentence: 이 번호로 전화해.\n",
            "\n",
            "-\n",
            "Input sentence: That's suicide.\n",
            "Correct Translation: 그것은 자살입니다.\n",
            "Decoded sentence: 그 약은 효과가 있었다.\n",
            "\n",
            "-\n",
            "Input sentence: Boil some water.\n",
            "Correct Translation: 물 좀 끓여.\n",
            "Decoded sentence: 우리는 그 사건을 검토할 필요가 있다.\n",
            "\n",
            "-\n",
            "Input sentence: Can you help me?\n",
            "Correct Translation: 저를 좀 도와 주실래요?\n",
            "Decoded sentence: 이 번호로 전화해.\n",
            "\n",
            "-\n",
            "Input sentence: Congratulations!\n",
            "Correct Translation: 축하해!\n",
            "Decoded sentence: 그게 와인을 고 해해?\n",
            "\n",
            "-\n",
            "Input sentence: Do you like rap?\n",
            "Correct Translation: 랩 좋아해요?\n",
            "Decoded sentence: 좋아하는 가수는 누구예요?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmG1kNGoIFh8",
        "colab_type": "code",
        "outputId": "88d07d63-b68d-4f86-f3e3-5248a9c92e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data = load_data()\n",
        "data = one_hot_vectorize(data)\n",
        "data = create_reverse_indicies(data)\n",
        "model, encoder_model, decoder_model = load_models()\n",
        "\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = data[\"encoder_input_data\"][seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq, data, encoder_model, decoder_model)\n",
        "    print('-')\n",
        "    print('Input sentence:', data['input_texts'][seq_index])\n",
        "    print('Correct Translation:', data['target_texts'][seq_index].strip(\"\\t\\n\"))\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 909\n",
            "Number of unique input tokens: 69\n",
            "Number of unique output tokens: 662\n",
            "Max sequence length for inputs: 124\n",
            "Max sequence length for outputs: 54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Who?\n",
            "Correct Translation: 누구?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Correct Translation: 안녕!\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Correct Translation: 절대 아니야.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Correct Translation: 그럴리가!\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Goodbye!\n",
            "Correct Translation: 안녕!\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sad.\n",
            "Correct Translation: 슬퍼.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Me, too.\n",
            "Correct Translation: 나도.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Perfect!\n",
            "Correct Translation: 완벽해!\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Shut up!\n",
            "Correct Translation: 시끄러워!\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Welcome.\n",
            "Correct Translation: 어서오세요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Welcome.\n",
            "Correct Translation: 환영합니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Cheer up!\n",
            "Correct Translation: 힘내!\n",
            "Decoded sentence: 톰은 그를 사랑한다.\n",
            "\n",
            "-\n",
            "Input sentence: Get lost.\n",
            "Correct Translation: 꺼져.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm ugly.\n",
            "Correct Translation: 나는 못 생겼다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: It hurts.\n",
            "Correct Translation: 아파.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Let's go!\n",
            "Correct Translation: 가자!\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Don't lie.\n",
            "Correct Translation: 거짓말 하지 마.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Don't lie.\n",
            "Correct Translation: 거짓말 하지 마세요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sorry.\n",
            "Correct Translation: 미안해.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sorry.\n",
            "Correct Translation: 미안해요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sorry.\n",
            "Correct Translation: 죄송합니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm sorry.\n",
            "Correct Translation: 유감입니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Of course.\n",
            "Correct Translation: 물론이죠.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Seriously?\n",
            "Correct Translation: 진심이야?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Take care.\n",
            "Correct Translation: 주의하세요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Be careful.\n",
            "Correct Translation: 조심해!\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: He is nice.\n",
            "Correct Translation: 걔 괜찮아.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Hold still.\n",
            "Correct Translation: 가만히 있으세요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Hold still.\n",
            "Correct Translation: 가만히 있어.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: How lovely!\n",
            "Correct Translation: 어찌나 사랑스러운지!\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I felt bad.\n",
            "Correct Translation: 난 기분이 나빴다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Is that OK?\n",
            "Correct Translation: 괜찮은 거예요?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Love hurts.\n",
            "Correct Translation: 사랑은 아프다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Boys do cry.\n",
            "Correct Translation: 남자애도 운다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I don't lie.\n",
            "Correct Translation: 나는 거짓말 하지 않습니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I don't lie.\n",
            "Correct Translation: 난 거짓말 안해.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I don't lie.\n",
            "Correct Translation: 나는 거짓말 하지 않아.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm nervous.\n",
            "Correct Translation: 긴장돼요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm nervous.\n",
            "Correct Translation: 떨려요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm shocked.\n",
            "Correct Translation: 충격이야.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: It's a pity.\n",
            "Correct Translation: 안타까워요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: What's that?\n",
            "Correct Translation: 저건 뭐야?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: You're mine.\n",
            "Correct Translation: 넌 내 거야.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: You're mine.\n",
            "Correct Translation: 당신은 나의 것입니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Blood is red.\n",
            "Correct Translation: 피는 붉다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Can I go now?\n",
            "Correct Translation: 이제 가도 되나요?\n",
            "Decoded sentence: 톰은 그를 사랑한다.\n",
            "\n",
            "-\n",
            "Input sentence: Come quickly!\n",
            "Correct Translation: 빨리 와!\n",
            "Decoded sentence: 그는 그 사전을 다고 했다.\n",
            "\n",
            "-\n",
            "Input sentence: Come quickly!\n",
            "Correct Translation: 빨리 오세요!\n",
            "Decoded sentence: 그는 그 사전을 다고 했다.\n",
            "\n",
            "-\n",
            "Input sentence: Don't eat it.\n",
            "Correct Translation: 먹지 마.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I don't know.\n",
            "Correct Translation: 나는 몰라요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I hate liars.\n",
            "Correct Translation: 난 거짓말쟁이가 싫어.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I need money.\n",
            "Correct Translation: 돈이 필요해요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Is that okay?\n",
            "Correct Translation: 괜찮은 거예요?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Is this mine?\n",
            "Correct Translation: 이거 내꺼니?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Is this wine?\n",
            "Correct Translation: 이게 와인이야?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: It's suicide.\n",
            "Correct Translation: 자살입니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Just keep it.\n",
            "Correct Translation: 그냥 그거 가져.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: We don't lie.\n",
            "Correct Translation: 우리는 거짓말을 하지 않아요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: We don't lie.\n",
            "Correct Translation: 우린 거짓말 안해.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: We're inside.\n",
            "Correct Translation: 우리 안에 들어와 있어.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: We're inside.\n",
            "Correct Translation: 우린 안에 있어요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: What is that?\n",
            "Correct Translation: 저것은 무엇입니까?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Can I ask why?\n",
            "Correct Translation: 이유를 물어봐도 돼?\n",
            "Decoded sentence: 톰은 그를 사랑한다.\n",
            "\n",
            "-\n",
            "Input sentence: Grab the rope.\n",
            "Correct Translation: 로프를 잡으세요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I am homesick.\n",
            "Correct Translation: 나 향수병 걸렸어.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I can't sleep.\n",
            "Correct Translation: 잠이 와.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I feel guilty.\n",
            "Correct Translation: 죄책감이 들어.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I hate myself.\n",
            "Correct Translation: 나는 내 자신이 싫어.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I smell blood.\n",
            "Correct Translation: 피 냄새가 납니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I use Firefox.\n",
            "Correct Translation: 나는 파이어폭스를 사용해.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I want to die.\n",
            "Correct Translation: 죽고 싶어요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I want to die.\n",
            "Correct Translation: 죽고 싶어.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'll kill him.\n",
            "Correct Translation: 나는 그를 죽일 것이다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm depressed.\n",
            "Correct Translation: 우울해.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Is that blood?\n",
            "Correct Translation: 그거 피야?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: My head hurts.\n",
            "Correct Translation: 머리가 아파요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Tom is honest.\n",
            "Correct Translation: 톰은 정직하다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: We want peace.\n",
            "Correct Translation: 우리는 평화를 원합니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Autumn is here.\n",
            "Correct Translation: 가을이 되었습니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Autumn is here.\n",
            "Correct Translation: 가을이 왔어요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Can I help you?\n",
            "Correct Translation: 제가 좀 도와 드릴까요?\n",
            "Decoded sentence: 톰은 그를 사랑한다.\n",
            "\n",
            "-\n",
            "Input sentence: Do you hear me?\n",
            "Correct Translation: 제 말이 들리세요?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: He was hard up.\n",
            "Correct Translation: 그는 돈에 쪼들리고 있었다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I don't buy it.\n",
            "Correct Translation: 못 믿어.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I like reading.\n",
            "Correct Translation: 독서를 좋아합니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I love lasagna.\n",
            "Correct Translation: 저는 라자냐를 좋아해요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I love my home.\n",
            "Correct Translation: 난 내 집이 좋아.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I study Korean.\n",
            "Correct Translation: 한국말을 공부합니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm very sorry.\n",
            "Correct Translation: 정말 미안해.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: I'm very sorry.\n",
            "Correct Translation: 정말 죄송합니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Keep Tom there.\n",
            "Correct Translation: 톰은 여기에 두세요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Only God knows.\n",
            "Correct Translation: 신만이 아실 것입니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Read this book.\n",
            "Correct Translation: 이 책 읽어.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Read this book.\n",
            "Correct Translation: 이 책을 읽으세요.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Sorry I'm late.\n",
            "Correct Translation: 늦어서 미안해.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: That's suicide.\n",
            "Correct Translation: 그것은 자살입니다.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Boil some water.\n",
            "Correct Translation: 물 좀 끓여.\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n",
            "-\n",
            "Input sentence: Can you help me?\n",
            "Correct Translation: 저를 좀 도와 주실래요?\n",
            "Decoded sentence: 톰은 그를 사랑한다.\n",
            "\n",
            "-\n",
            "Input sentence: Congratulations!\n",
            "Correct Translation: 축하해!\n",
            "Decoded sentence: 그는 그 사전을 다고 했다.\n",
            "\n",
            "-\n",
            "Input sentence: Do you like rap?\n",
            "Correct Translation: 랩 좋아해요?\n",
            "Decoded sentence: 톰은 그를 무엇을 했어.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2VtmKOl-_AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}